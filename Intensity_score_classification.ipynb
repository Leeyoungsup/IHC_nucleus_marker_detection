{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "917cc018",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "import yaml\n",
    "from nets import nn\n",
    "import torchvision\n",
    "device=torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"device:\",device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b2e0495",
   "metadata": {},
   "source": [
    "tumor cell binary detection model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27f7c692",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('utils/args.yaml', errors='ignore') as f:\n",
    "    params = yaml.safe_load(f)\n",
    "def collate_fn1(batch):\n",
    "    samples, cls, box, indices = zip(*batch)\n",
    "\n",
    "    cls = torch.cat(cls, dim=0)\n",
    "    box = torch.cat(box, dim=0)\n",
    "\n",
    "    new_indices = list(indices)\n",
    "    for i in range(len(indices)):\n",
    "        new_indices[i] += i\n",
    "    indices = torch.cat(new_indices, dim=0)\n",
    "\n",
    "    targets = {'cls': cls,\n",
    "                'box': box,\n",
    "                'idx': indices}\n",
    "    return torch.stack(samples, dim=0), targets\n",
    "def wh2xy(x):\n",
    "    y = x.clone() if isinstance(x, torch.Tensor) else np.copy(x)\n",
    "    y[:, 0] = x[:, 0] - x[:, 2] / 2  # top left x\n",
    "    y[:, 1] = x[:, 1] - x[:, 3] / 2  # top left y\n",
    "    y[:, 2] = x[:, 0] + x[:, 2] / 2  # bottom right x\n",
    "    y[:, 3] = x[:, 1] + x[:, 3] / 2  # bottom right y\n",
    "    return y\n",
    "   \n",
    "def non_max_suppression(outputs, confidence_threshold=0.001, iou_threshold=0.65, class_thresholds=None):\n",
    "    \"\"\"\n",
    "    빠른 클래스별 NMS - 성능 최적화 버전\n",
    "    \"\"\"\n",
    "    max_wh = 7680\n",
    "    max_det = 300\n",
    "    max_nms = 30000\n",
    "\n",
    "    bs = outputs.shape[0]\n",
    "    nc = outputs.shape[1] - 4\n",
    "    \n",
    "    # 빠른 필터링을 위해 가장 낮은 threshold 사용\n",
    "    min_conf = confidence_threshold\n",
    "    if class_thresholds:\n",
    "        min_conf = min(min(class_thresholds.values()), confidence_threshold)\n",
    "    \n",
    "    # 전체 confidence가 낮은 것들 먼저 제거\n",
    "    xc = outputs[:, 4:4 + nc].amax(1) > min_conf\n",
    "    \n",
    "    output = [torch.zeros((0, 6), device=outputs.device)] * bs\n",
    "    \n",
    "    for xi, x in enumerate(outputs):  # image index, image inference\n",
    "        x = x.transpose(0, -1)[xc[xi]]\n",
    "        \n",
    "        if not x.shape[0]:\n",
    "            continue\n",
    "\n",
    "        # 박스와 클래스 분리\n",
    "        box, cls = x.split((4, nc), 1)\n",
    "        box = wh2xy(box)\n",
    "        \n",
    "        # 각 검출의 최고 클래스와 confidence 찾기\n",
    "        conf, j = cls.max(1, keepdim=True)\n",
    "        x = torch.cat((box, conf, j.float()), 1)\n",
    "        \n",
    "        # 클래스별 threshold 적용 (간단한 방식)\n",
    "        if class_thresholds:\n",
    "            keep = torch.zeros(x.shape[0], dtype=torch.bool, device=x.device)\n",
    "            for i, detection in enumerate(x):\n",
    "                class_id = int(detection[5].item())\n",
    "                threshold = class_thresholds.get(class_id, confidence_threshold)\n",
    "                if detection[4].item() >= threshold:\n",
    "                    keep[i] = True\n",
    "            x = x[keep]\n",
    "        else:\n",
    "            x = x[x[:, 4] > confidence_threshold]\n",
    "        \n",
    "        if not x.shape[0]:\n",
    "            continue\n",
    "            \n",
    "        # confidence로 정렬하고 상위 max_nms개만 유지\n",
    "        x = x[x[:, 4].argsort(descending=True)[:max_nms]]\n",
    "        \n",
    "        # 빠른 NMS - PyTorch 내장 함수 사용\n",
    "        c = x[:, 5:6] * max_wh  # 클래스별 offset\n",
    "        boxes = x[:, :4] + c\n",
    "        scores = x[:, 4]\n",
    "        \n",
    "        # NMS 적용\n",
    "        keep = torchvision.ops.nms(boxes, scores, iou_threshold)\n",
    "        if keep.shape[0] > max_det:\n",
    "            keep = keep[:max_det]\n",
    "        \n",
    "        output[xi] = x[keep]\n",
    "    \n",
    "    return output\n",
    "    \n",
    "def pred_patch(torch_patch, model, start_x, start_y, magnification):\n",
    "    model.eval()\n",
    "    \n",
    "    # HnE 세포 분류를 위한 클래스별 개별 confidence threshold 설정\n",
    "    class_thresholds = {\n",
    "        0: 0.3,  # Neutrophil\n",
    "        1: 0.3,  # Epithelial\n",
    "\n",
    "    }\n",
    "    \n",
    "    # 각 클래스별 세포 리스트 (임시로 기존 변수명 유지)\n",
    "    cells_list = []  # 모든 검출된 세포를 여기에 저장\n",
    "\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        with torch.amp.autocast('cuda'):\n",
    "            pred = model(torch_patch)\n",
    "        \n",
    "        # 빠른 NMS 적용\n",
    "        results = non_max_suppression(pred, confidence_threshold=0.3, \n",
    "                                    iou_threshold=0.3, class_thresholds=class_thresholds)\n",
    "        \n",
    "        if len(results[0]) > 0:\n",
    "            # 벡터화된 처리로 속도 향상\n",
    "            detections = results[0]\n",
    "            xyxy = detections[:, :4]\n",
    "            confs = detections[:, 4]\n",
    "            cls_ids = detections[:, 5]\n",
    "            \n",
    "            # 중심점 계산 (벡터화)\n",
    "            centers_x = (xyxy[:, 0] + xyxy[:, 2]) / 2\n",
    "            centers_y = (xyxy[:, 1] + xyxy[:, 3]) / 2\n",
    "            \n",
    "            # 실제 좌표 계산\n",
    "            actual_x = start_x + centers_x * magnification\n",
    "            actual_y = start_y + centers_y * magnification\n",
    "            \n",
    "            # 모든 클래스의 세포를 cells_list 리스트에 저장 (벡터화)\n",
    "            for i in range(len(detections)):\n",
    "                cls_id = int(cls_ids[i].item())\n",
    "                cell_data = {\n",
    "                    'x': actual_x[i].item(), \n",
    "                    'y': actual_y[i].item(), \n",
    "                    'cls_id': cls_id,\n",
    "                    'confidence': confs[i].item()\n",
    "                }\n",
    "                \n",
    "                # 모든 세포를 cells_list에 저장 (XML 생성 함수에서 cls_id로 구분)\n",
    "                cells_list.append(cell_data)\n",
    "    \n",
    "    return cells_list\n",
    "\n",
    "# 모델 및 파라미터 준비\n",
    "\n",
    "model_path='../../model/nucleus_marker_yolov11/best_model.pt'\n",
    "model = nn.yolo_v11_m(len(params['names'])).to(device)\n",
    "checkpoint = torch.load(model_path, map_location=device, weights_only=False)\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca9f6e12",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_list=glob('../../data/BCData/images/train/*.png')\n",
    "i=16\n",
    "image=Image.open(image_list[i]).convert('RGB')\n",
    "image=np.array(image)\n",
    "cell_list = pred_patch((torch.from_numpy(image).permute(2, 0, 1).unsqueeze(0).float() / 255.0).to(device), model, 0, 0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b386386b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cell_intensity_classification(image, cell_list):\n",
    "    hsi_image=cv2.cvtColor(image, cv2.COLOR_RGB2HSV)\n",
    "    size=15\n",
    "    for i in range(len(cell_list)):\n",
    "        cell_info=cell_list[i]\n",
    "        cell_image=255-hsi_image[int(cell_info['y']-size):int(cell_info['y']+size), int(cell_info['x']-size):int(cell_info['x']+size),2]\n",
    "        if cell_info['cls_id']==1:\n",
    "            intensity_score=np.mean(cell_image)\n",
    "            if intensity_score>170:\n",
    "                cell_list[i]['cls_id']=3\n",
    "            elif intensity_score>130:\n",
    "                cell_list[i]['cls_id']=2\n",
    "            else:\n",
    "                cell_list[i]['cls_id']=1\n",
    "    return cell_list    \n",
    "cell_list=cell_intensity_classification(image, cell_list)\n",
    "class_0_plotted = False\n",
    "class_1_plotted = False\n",
    "class_2_plotted = False\n",
    "class_3_plotted = False\n",
    "plt.imshow(image)\n",
    "for cell in cell_list:\n",
    "    x = cell['x']\n",
    "    y = cell['y']\n",
    "    cls_id = cell['cls_id']\n",
    "    confidence = cell['confidence']\n",
    "    if cls_id==0:\n",
    "        if not class_0_plotted:\n",
    "            plt.scatter(x, y, c='g', s=30, alpha=0.6, label=f'Class 0')\n",
    "            class_0_plotted = True\n",
    "        else:\n",
    "            plt.scatter(x, y, c='g', s=30, alpha=0.6)\n",
    "    elif cls_id==1:\n",
    "        if not class_1_plotted:\n",
    "            plt.scatter(x, y, c='y', s=30, alpha=0.6, label=f'Class 1')\n",
    "            class_1_plotted = True\n",
    "        else:\n",
    "            plt.scatter(x, y, c='y', s=30, alpha=0.6)\n",
    "    elif cls_id==2:\n",
    "        if class_2_plotted==False:\n",
    "            plt.scatter(x, y, c='b', s=30, alpha=0.6, label=f'Class 2')\n",
    "            class_2_plotted = True\n",
    "        else:\n",
    "            plt.scatter(x, y, c='b', s=30, alpha=0.6)\n",
    "\n",
    "    elif cls_id==3:\n",
    "        if class_3_plotted==False:\n",
    "            plt.scatter(x, y, c='r', s=30, alpha=0.6, label='Class 3')\n",
    "            class_3_plotted = True\n",
    "        else:   \n",
    "            plt.scatter(x, y, c='r', s=30, alpha=0.6)\n",
    "\n",
    "\n",
    "plt.legend()\n",
    "plt.title('Detected Cells by Class')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e78948c",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_list=glob('../../data/BCData/images/train/*.png')\n",
    "i=10\n",
    "image=Image.open(image_list[i]).convert('RGB')\n",
    "image=np.array(image)\n",
    "hsi_image=cv2.cvtColor(image,cv2.COLOR_RGB2HSV)\n",
    "plt.imshow(image)\n",
    "plt.show()\n",
    "plt.figure(figsize=(15,10))\n",
    "plt.subplot(2,3,1)\n",
    "plt.imshow(image[:,:,0])\n",
    "plt.title('R channel')\n",
    "plt.subplot(2,3,2)\n",
    "plt.imshow(image[:,:,1])\n",
    "plt.title('G channel')\n",
    "plt.subplot(2,3,3)\n",
    "plt.imshow(image[:,:,2])\n",
    "plt.title('B channel')\n",
    "plt.subplot(2,3,4)\n",
    "plt.imshow(hsi_image[:,:,0])\n",
    "plt.title('Hue channel')\n",
    "plt.subplot(2,3,5)\n",
    "plt.imshow(hsi_image[:,:,1])\n",
    "plt.title('Saturation channel')\n",
    "plt.subplot(2,3,6)\n",
    "plt.imshow(hsi_image[:,:,2])\n",
    "plt.title('Intensity channel')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
