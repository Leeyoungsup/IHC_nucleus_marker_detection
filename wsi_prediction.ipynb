{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b39ece3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import warnings\n",
    "from argparse import ArgumentParser\n",
    "import matplotlib.patches as patches\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "import cv2\n",
    "from torch.utils import data\n",
    "# 개별 json 라벨 파일을 이용해 학습 데이터 리스트 생성\n",
    "from glob import glob\n",
    "import xml.etree.ElementTree as ET\n",
    "from xml.dom import minidom\n",
    "import os\n",
    "from nets import nn\n",
    "from utils import util\n",
    "from utils.dataset import Dataset\n",
    "from torch.utils import data\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import openslide\n",
    "import copy\n",
    "import random\n",
    "from time import time\n",
    "\n",
    "import math\n",
    "import numpy\n",
    "import torch\n",
    "import torchvision\n",
    "from torch.nn.functional import cross_entropy\n",
    "device=torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"device:\",device)\n",
    "params={'names':{\n",
    "            0: \"Neutrophil\",\n",
    "            1: \"Epithelial\",\n",
    "            2: \"Lymphocyte\",\n",
    "            3: \"Plasma\",\n",
    "            4: \"Eosinophil\",\n",
    "            5: \"Connective tissue\"\n",
    "        }}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b649b328",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dir='../../model/HnE_cell_detection/yolov11/'\n",
    "model = nn.yolo_v11_m(len(params['names'])).to(device)\n",
    "checkpoint_path = os.path.join(save_dir, 'best_model_m.pt')\n",
    "if os.path.exists(checkpoint_path):\n",
    "    checkpoint = torch.load(checkpoint_path, map_location=device,weights_only=False)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    \n",
    "def wh2xy(x):\n",
    "    y = x.clone() if isinstance(x, torch.Tensor) else numpy.copy(x)\n",
    "    y[:, 0] = x[:, 0] - x[:, 2] / 2  # top left x\n",
    "    y[:, 1] = x[:, 1] - x[:, 3] / 2  # top left y\n",
    "    y[:, 2] = x[:, 0] + x[:, 2] / 2  # bottom right x\n",
    "    y[:, 3] = x[:, 1] + x[:, 3] / 2  # bottom right y\n",
    "    return y\n",
    "   \n",
    "def non_max_suppression(outputs, confidence_threshold=0.001, iou_threshold=0.65, class_thresholds=None):\n",
    "    \"\"\"\n",
    "    빠른 클래스별 NMS - 성능 최적화 버전\n",
    "    \"\"\"\n",
    "    max_wh = 7680\n",
    "    max_det = 300\n",
    "    max_nms = 30000\n",
    "\n",
    "    bs = outputs.shape[0]\n",
    "    nc = outputs.shape[1] - 4\n",
    "    \n",
    "    # 빠른 필터링을 위해 가장 낮은 threshold 사용\n",
    "    min_conf = confidence_threshold\n",
    "    if class_thresholds:\n",
    "        min_conf = min(min(class_thresholds.values()), confidence_threshold)\n",
    "    \n",
    "    # 전체 confidence가 낮은 것들 먼저 제거\n",
    "    xc = outputs[:, 4:4 + nc].amax(1) > min_conf\n",
    "    \n",
    "    output = [torch.zeros((0, 6), device=outputs.device)] * bs\n",
    "    \n",
    "    for xi, x in enumerate(outputs):  # image index, image inference\n",
    "        x = x.transpose(0, -1)[xc[xi]]\n",
    "        \n",
    "        if not x.shape[0]:\n",
    "            continue\n",
    "\n",
    "        # 박스와 클래스 분리\n",
    "        box, cls = x.split((4, nc), 1)\n",
    "        box = wh2xy(box)\n",
    "        \n",
    "        # 각 검출의 최고 클래스와 confidence 찾기\n",
    "        conf, j = cls.max(1, keepdim=True)\n",
    "        x = torch.cat((box, conf, j.float()), 1)\n",
    "        \n",
    "        # 클래스별 threshold 적용 (간단한 방식)\n",
    "        if class_thresholds:\n",
    "            keep = torch.zeros(x.shape[0], dtype=torch.bool, device=x.device)\n",
    "            for i, detection in enumerate(x):\n",
    "                class_id = int(detection[5].item())\n",
    "                threshold = class_thresholds.get(class_id, confidence_threshold)\n",
    "                if detection[4].item() >= threshold:\n",
    "                    keep[i] = True\n",
    "            x = x[keep]\n",
    "        else:\n",
    "            x = x[x[:, 4] > confidence_threshold]\n",
    "        \n",
    "        if not x.shape[0]:\n",
    "            continue\n",
    "            \n",
    "        # confidence로 정렬하고 상위 max_nms개만 유지\n",
    "        x = x[x[:, 4].argsort(descending=True)[:max_nms]]\n",
    "        \n",
    "        # 빠른 NMS - PyTorch 내장 함수 사용\n",
    "        c = x[:, 5:6] * max_wh  # 클래스별 offset\n",
    "        boxes = x[:, :4] + c\n",
    "        scores = x[:, 4]\n",
    "        \n",
    "        # NMS 적용\n",
    "        keep = torchvision.ops.nms(boxes, scores, iou_threshold)\n",
    "        if keep.shape[0] > max_det:\n",
    "            keep = keep[:max_det]\n",
    "        \n",
    "        output[xi] = x[keep]\n",
    "    \n",
    "    return output\n",
    "    \n",
    "def pred_patch(torch_patch, model, start_x, start_y, magnification):\n",
    "    model.eval()\n",
    "    \n",
    "    # HnE 세포 분류를 위한 클래스별 개별 confidence threshold 설정\n",
    "    class_thresholds = {\n",
    "        0: 0.05,  # Neutrophil\n",
    "        1: 0.05,  # Epithelial\n",
    "        2: 0.05,  # Lymphocyte\n",
    "        3: 0.05,  # Plasma\n",
    "        4: 0.05,  # Eosinophil\n",
    "        5: 0.05   # Connective tissue\n",
    "    }\n",
    "    \n",
    "    # 각 클래스별 세포 리스트 (임시로 기존 변수명 유지)\n",
    "    cells_list = []  # 모든 검출된 세포를 여기에 저장\n",
    "\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        with torch.amp.autocast('cuda'):\n",
    "            pred = model(torch_patch)\n",
    "        \n",
    "        # 빠른 NMS 적용\n",
    "        results = non_max_suppression(pred, confidence_threshold=0.05, \n",
    "                                    iou_threshold=0.3, class_thresholds=class_thresholds)\n",
    "        \n",
    "        if len(results[0]) > 0:\n",
    "            # 벡터화된 처리로 속도 향상\n",
    "            detections = results[0]\n",
    "            xyxy = detections[:, :4]\n",
    "            confs = detections[:, 4]\n",
    "            cls_ids = detections[:, 5]\n",
    "            \n",
    "            # 중심점 계산 (벡터화)\n",
    "            centers_x = (xyxy[:, 0] + xyxy[:, 2]) / 2\n",
    "            centers_y = (xyxy[:, 1] + xyxy[:, 3]) / 2\n",
    "            \n",
    "            # 실제 좌표 계산\n",
    "            actual_x = start_x + centers_x * magnification\n",
    "            actual_y = start_y + centers_y * magnification\n",
    "            \n",
    "            # 모든 클래스의 세포를 cells_list 리스트에 저장 (벡터화)\n",
    "            for i in range(len(detections)):\n",
    "                cls_id = int(cls_ids[i].item())\n",
    "                cell_data = {\n",
    "                    'x': actual_x[i].item(), \n",
    "                    'y': actual_y[i].item(), \n",
    "                    'cls_id': cls_id,\n",
    "                    'confidence': confs[i].item()\n",
    "                }\n",
    "                \n",
    "                # 모든 세포를 cells_list에 저장 (XML 생성 함수에서 cls_id로 구분)\n",
    "                cells_list.append(cell_data)\n",
    "    \n",
    "    return cells_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eb2b41c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def save_patch_cells_to_json(cells_list, temp_dir, patch_id):\n",
    "    \"\"\"각 패치별로 개별 JSON 파일에 저장 (파싱 없음!)\"\"\"\n",
    "    if not cells_list:\n",
    "        return\n",
    "    \n",
    "    patch_json_path = os.path.join(temp_dir, f\"patch_{patch_id}.json\")\n",
    "    \n",
    "    # 직접 저장 (파일 읽기/파싱 전혀 없음!)\n",
    "    with open(patch_json_path, 'w') as f:\n",
    "        json.dump(cells_list, f)\n",
    "\n",
    "def merge_patch_jsons_to_xml(temp_dir, xml_path):\n",
    "    \"\"\"temp 폴더의 모든 개별 JSON 파일을 병합하여 XML로 변환\"\"\"\n",
    "    \n",
    "    # temp 폴더의 모든 JSON 파일 수집\n",
    "    json_files = glob(os.path.join(temp_dir, \"patch_*.json\"))\n",
    "    all_cells = []\n",
    "    \n",
    "    print(f\"📄 {len(json_files)}개의 패치 JSON 파일 병합 중...\")\n",
    "    \n",
    "    # 모든 JSON 파일에서 세포 데이터 수집\n",
    "    for json_file in json_files:\n",
    "        with open(json_file, 'r') as f:\n",
    "            patch_cells = json.load(f)\n",
    "            all_cells.extend(patch_cells)\n",
    "    \n",
    "    # HnE 세포 분류를 위한 클래스별 색상 매핑\n",
    "    class_colors = {\n",
    "        0: \"#FFA500\",  # Neutrophil - 주황색\n",
    "        1: \"#008000\",  # Epithelial - 녹색\n",
    "        2: \"#FF0000\",  # Lymphocyte - 빨간색\n",
    "        3: \"#87CEEB\",  # Plasma - 하늘색\n",
    "        4: \"#0000FF\",  # Eosinophil - 파란색sssssdasdasdasdasdasdasdasdasdasdㅁㄴㅇsds\n",
    "        5: \"#FFFF00\"   # Connective tissue - 노란색\n",
    "    }\n",
    "    \n",
    "    class_names = {\n",
    "        0: \"Neutrophil\",\n",
    "        1: \"Epithelial\", \n",
    "        2: \"Lymphocyte\",\n",
    "        3: \"Plasma\",\n",
    "        4: \"Eosinophil\",\n",
    "        5: \"Connective tissue\"\n",
    "    }\n",
    "    \n",
    "    # 루트 엘리먼트 생성\n",
    "    root = ET.Element(\"ASAP_Annotations\")\n",
    "    \n",
    "    # Annotations 엘리먼트 생성\n",
    "    annotations = ET.SubElement(root, \"Annotations\")\n",
    "    \n",
    "    # 한 번에 모든 세포 추가\n",
    "    annotation_id = 0\n",
    "    for cell in all_cells:\n",
    "        cls_id = cell.get('cls_id', 0)\n",
    "        \n",
    "        annotation = ET.SubElement(annotations, \"Annotation\")\n",
    "        annotation.set(\"Name\", f\"Annotation {annotation_id}\")\n",
    "        annotation.set(\"Type\", \"Dot\")\n",
    "        annotation.set(\"PartOfGroup\", class_names.get(cls_id, f\"Class_{cls_id}\"))\n",
    "        annotation.set(\"Color\", class_colors.get(cls_id, \"#FFFFFF\"))\n",
    "        \n",
    "        coordinates = ET.SubElement(annotation, \"Coordinates\")\n",
    "        coordinate = ET.SubElement(coordinates, \"Coordinate\")\n",
    "        coordinate.set(\"Order\", \"0\")\n",
    "        coordinate.set(\"X\", str(float(cell['x'])))\n",
    "        coordinate.set(\"Y\", str(float(cell['y'])))\n",
    "        \n",
    "        annotation_id += 1\n",
    "    \n",
    "    # AnnotationGroups 엘리먼트 생성\n",
    "    annotation_groups = ET.SubElement(root, \"AnnotationGroups\")\n",
    "    \n",
    "    # 각 클래스별 그룹 생성\n",
    "    for cls_id, class_name in class_names.items():\n",
    "        group = ET.SubElement(annotation_groups, \"Group\")\n",
    "        group.set(\"Name\", class_name)\n",
    "        group.set(\"PartOfGroup\", \"None\")\n",
    "        group.set(\"Color\", class_colors.get(cls_id, \"#FFFFFF\"))\n",
    "        attributes = ET.SubElement(group, \"Attributes\")\n",
    "    \n",
    "    # XML 저장\n",
    "    rough_string = ET.tostring(root, 'unicode')\n",
    "    reparsed = minidom.parseString(rough_string)\n",
    "    pretty_xml = reparsed.toprettyxml(indent=\"\t\")\n",
    "    \n",
    "    # <?xml version... 라인을 원하는 형태로 수정\n",
    "    lines = pretty_xml.split('\\n')\n",
    "    lines[0] = '<?xml version=\"1.0\"?>'\n",
    "    pretty_xml = '\\n'.join(lines[1:])  # 빈 라인 제거\n",
    "    \n",
    "    with open(xml_path, 'w', encoding='utf-8') as f:\n",
    "        f.write(pretty_xml)\n",
    "    \n",
    "    print(f\"✅ XML 변환 완료: {len(all_cells)}개 세포\")\n",
    "    return len(all_cells)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2021d19",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyvips\n",
    "import shutil\n",
    "\n",
    "slide_path=glob('../../data/*_HnE/*.ndpi')\n",
    "image_size=1024 # 모델 입력 크기\n",
    "origin_mpp=0.25\n",
    "output_mpp=0.5\n",
    "original_size=int(image_size*output_mpp/origin_mpp) #1122\n",
    "magnification=original_size/image_size\n",
    "count=0\n",
    "\n",
    "for i in range(len(slide_path)):\n",
    "    file_name=os.path.basename(slide_path[i]).split('.')[0]\n",
    "    slide=openslide.OpenSlide(slide_path[i])\n",
    "    thumbnail=slide.get_thumbnail((slide.dimensions[0]//64, slide.dimensions[1]//64))\n",
    "    slide = pyvips.Image.new_from_file(slide_path[i])\n",
    "\n",
    "    thumb_mask=cv2.threshold(255-np.array(thumbnail.convert('L')),30,255,cv2.THRESH_BINARY)[1]\n",
    "    thumb_mask=cv2.morphologyEx(thumb_mask,cv2.MORPH_CLOSE,np.ones((15,15),np.uint8))\n",
    "    thumb_mask=cv2.morphologyEx(thumb_mask,cv2.MORPH_OPEN,np.ones((5,5),np.uint8))\n",
    "    \n",
    "    # 파일 경로 설정\n",
    "    output_xml_path = f\"../../results/BR_HnE/cell_detection/{file_name}.xml\"\n",
    "    temp_dir = f\"../../results/BR_HnE/cell_detection/{file_name}_temp\"\n",
    "    os.makedirs(\"../../results/BR_HnE/cell_detection\", exist_ok=True)\n",
    "    \n",
    "    # temp 폴더 초기화 (기존 폴더 삭제 후 새로 생성)\n",
    "    if os.path.exists(temp_dir):\n",
    "        shutil.rmtree(temp_dir)\n",
    "    os.makedirs(temp_dir)\n",
    "    \n",
    "    total_cells_detected = 0\n",
    "    patch_counter = 0  # 패치 ID 카운터\n",
    "    row_pbar = tqdm(range(slide.width//image_size-1), total=slide.width//image_size-1)\n",
    "    \n",
    "    for patch_row in row_pbar:\n",
    "        for patch_col in range(slide.height//image_size-1):\n",
    "            if np.sum(thumb_mask[(patch_col*image_size)//64:((patch_col+1)*image_size)//64,(patch_row*image_size)//64:((patch_row+1)*image_size)//64])>0:\n",
    "                count+=1\n",
    "                patch=slide.crop(patch_row*image_size, patch_col*image_size, image_size, image_size)\n",
    "                patch=np.ndarray(buffer=patch.write_to_memory(),\n",
    "                            dtype=np.uint8,\n",
    "                            shape=[patch.height, patch.width, patch.bands])\n",
    "                patch = cv2.resize(np.array(patch)[:,:,:3], (512, 512))\n",
    "                torch_patch=torch.from_numpy(patch).permute(2,0,1).unsqueeze(0).float()/255.\n",
    "                torch_patch=torch_patch.to(device)\n",
    "                cell_list = pred_patch(torch_patch, model, patch_row*image_size, patch_col*image_size, 2)\n",
    "                \n",
    "                # 🚀 개별 JSON 파일로 저장 (파일 파싱 전혀 없음!)\n",
    "                if len(cell_list) > 0:\n",
    "                    save_patch_cells_to_json(cell_list, temp_dir, patch_counter)\n",
    "                    total_cells_detected += len(cell_list)\n",
    "                \n",
    "                patch_counter += 1  # 패치 ID 증가\n",
    "                s = f\"처리된 패치: {count}, 총 검출된 세포: {total_cells_detected}\"\n",
    "                row_pbar.set_description(f'{s}')\n",
    "\n",
    "    # 🎯 처리 완료 후 모든 개별 JSON → XML 일괄 변환\n",
    "    print(f\"\\n📄 개별 JSON 파일들 병합하여 XML 변환 중...\")\n",
    "    final_cell_count = merge_patch_jsons_to_xml(temp_dir, output_xml_path)\n",
    "    \n",
    "    # temp 폴더 전체 삭제\n",
    "    shutil.rmtree(temp_dir)\n",
    "    \n",
    "    print(f\"🎯 WSI 처리 완료! 총 {final_cell_count}개 세포 검출됨\")\n",
    "    print(f\"📄 XML 파일 저장 위치: {output_xml_path}\")\n",
    "    print(f\"🗑️  임시 폴더 정리 완료\")\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
